# -*- coding: utf-8 -*-
# author: liyang
# time: 2025/4/17 10:21
import sys
from PyQt5.QtWidgets import QApplication
import time

from PyQt5.QtCore import pyqtSignal, QRect, QSize, Qt, QThread
from PyQt5.QtGui import QPainter, QImage, QPen
from PyQt5.QtWidgets import QWidget
import cv2
from PyQt5.uic import loadUi

from lyAiDetect import *

import numpy as np

from datetime import datetime

#å–è§†é¢‘æµçš„åœ°å€
class lyVideoStreamThread(QThread):
    matdict_signal = pyqtSignal(dict)

    startrecord_signal = pyqtSignal(dict)
    stoprecord_signal = pyqtSignal()
    widthheight_signal = pyqtSignal(list)

    recordtime_singal = pyqtSignal(str)

    sendframeindex_signal = pyqtSignal(int)

    def __init__(self):
        super().__init__()
        self._running = False
        self._paused = False  # æ–°å¢æš‚åœçŠ¶æ€æ ‡å¿—

        self._timeflag=0
        self._flag_startrecord=False
        self._flag_stoprecord=False
        self._flag_loop=False

    def setrtsp(self,path):
        self.path = path

    def format_time(self,seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸º HH:MM:SS æ ¼å¼"""
        hours, remainder = divmod(seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"
    def run(self):
        try:
            self.cap = cv2.VideoCapture(self.path)
            if not self.cap.isOpened():
                print("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return

            flag_mp4=False
            if self.path.endswith(".mp4") or self.path.endswith(".avi"):
                flag_mp4 = True

            self._timeflag=0   # ç”¨æ¥æ˜¾ç¤ºå½•åˆ¶äº†å¤šå°‘ç§’

            self.start_time=0
            self.end_time=0

            self._running = True # ç”¨æ¥æ§åˆ¶çº¿ç¨‹çš„è¿è¡ŒçŠ¶æ€
            # è·å–è§†é¢‘å¸§ç‡
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            width = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
            height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)

            self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

            # æŠŠè§†é¢‘çš„å®½é«˜å‘åˆ°AIå¤„ç†çº¿ç¨‹ä¸­
            self.widthheight_signal.emit([width,height])



            self.frame_index = 0

            while self._running:
                if not self._paused:  # éæš‚åœçŠ¶æ€æ‰å¤„ç†å¸§
                    ret, frame = self.cap.read()

                    if  self._flag_loop and  not ret:
                        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                        self.frame_index = 0
                        continue

                    if ret:
                        self.sendframeindex_signal.emit(self.frame_index)
                        self.matdict_signal.emit({self.frame_index:frame})
                        # æ˜¯çœŸçš„å°±å¼€å¯å½•åˆ¶ ï¼Œå¹¶å¤„AIå¤„ç†
                        if(self._flag_startrecord):
                            if self._timeflag==0:
                                self.start_time = time.time()
                                self._timeflag+=1

                            self.startrecord_signal.emit({self.frame_index:frame})
                            self.end_time = time.time()
                            self.recordtime_singal.emit(self.format_time(self.end_time-self.start_time))

                        if flag_mp4:
                            time.sleep(1/fps)

                        self.frame_index += 1
                    else:
                        break
                else:
                     time.sleep(1) # æš‚åœæ—¶é™ä½CPUå ç”¨
        except Exception as e:
            print(e)

        # âœ… ä¸Šä¸€å¸§æ§åˆ¶
    def prev_frame(self):
        if not self._paused or not self.cap or not self.cap.isOpened():
            print("æœªå¤„äºæš‚åœçŠ¶æ€æˆ–è§†é¢‘æ— æ•ˆ")
            return

        self.frame_index = max(0, self.frame_index - 1)
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.frame_index)
        ret, frame = self.cap.read()
        if ret:
            self.sendframeindex_signal.emit(self.frame_index)
            self.matdict_signal.emit({self.frame_index: frame})
            print(f"è·³è½¬åˆ°ä¸Šä¸€å¸§ï¼š{self.frame_index}")
        else:
            print("æ— æ³•è¯»å–ä¸Šä¸€å¸§")

        # âœ… ä¸‹ä¸€å¸§æ§åˆ¶
    def next_frame(self):
        if not self._paused or not self.cap or not self.cap.isOpened():
            print("æœªå¤„äºæš‚åœçŠ¶æ€æˆ–è§†é¢‘æ— æ•ˆ")
            return

        if self.frame_index + 1 >= self.total_frames:
            print("å·²ç»æ˜¯æœ€åä¸€å¸§")
            return

        self.frame_index += 1
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.frame_index)
        ret, frame = self.cap.read()
        if ret:
            self.sendframeindex_signal.emit(self.frame_index)
            self.matdict_signal.emit({self.frame_index: frame})
            print(f"è·³è½¬åˆ°ä¸‹ä¸€å¸§ï¼š{self.frame_index}")
        else:
            print("æ— æ³•è¯»å–ä¸‹ä¸€å¸§")

    def pause(self):
        """æš‚åœè§†é¢‘æµï¼ˆä¿æŒçº¿ç¨‹è¿è¡Œä½†ä¸å‘é€å¸§ï¼‰"""
        self._paused = True
        print(f"è§†é¢‘å·²æš‚åœ")

    def resume(self):
        """æ¢å¤è§†é¢‘æµ"""
        self._paused = False
        print(f"è§†é¢‘å·²æ¢å¤")

    def stop(self):
        """å®Œå…¨åœæ­¢çº¿ç¨‹"""
        self._running = False
        self._paused = False
        self.wait()
        print(f"è§†é¢‘å·²åœæ­¢")

    def setstartrecord(self):
        self._flag_startrecord=True
        self._flag_stoprecord=False
        print("å¯åŠ¨å½•åˆ¶")

    def setstoprecord(self):
        self._flag_startrecord=False
        self._flag_stoprecord=True
        self._timeflag == 0  #è®¡ç®—æ—¶é—´
        self.start_time = 0
        self.end_time = 0
        print("åœæ­¢å½•åˆ¶")

    def setflagloop(self):
        self._flag_loop=True


#è¿™æ˜¯ä¸€ä¸ªè§†é¢‘æ’­æ”¾æ§ä»¶
class lyVideoPlayer(QWidget):
    my_signal = pyqtSignal(dict)
    uuid_signal = pyqtSignal(str)
    paramstr_signal = pyqtSignal(str)
    def __init__(self, parent=None):
        super().__init__(parent)

        self.path = "./testvideos/pose_video.mp4"
        self.jsonpath = None
        self.storepath = "./testvideos"
        self.videostream_thread = lyVideoStreamThread()
        self.videoframeai_thread = AIFrameThread()
        self.flag_startai = False  # æ§åˆ¶AIå½•åˆ¶å’Œåœæ­¢å½•åˆ¶

        self.flag_loop = False  # æ˜¯å¦å¾ªç¯æ’­æ”¾
        self.frame = []
        self.frameid = 0
        self.flag_nextpre=False   # æ§åˆ¶ä¸Šä¸€å¸§ä¸‹ä¸€å¸§

        self.listdata = []
        self.id1json_data = []
        self.id2json_data = []
        loadUi('videoborad_page.ui',self)

        self.init_slot()

    def init_slot(self):

        # æ’­æ”¾è§†é¢‘
        self.pushButton.clicked.connect(self.start_videoborad)

        # æš‚åœæ’­æ”¾
        self.pushButton_2.clicked.connect(self.pause_videoborad)

        # æ¢å¤æ’­æ”¾
        self.pushButton_9.clicked.connect(self.resume_videoborad)

        # åœæ­¢æ’­æ”¾
        self.pushButton_8.clicked.connect(self.stop_videoborad)

        # å¯åŠ¨å½•åˆ¶
        self.pushButton_3.clicked.connect(self.start_videorecord)

        # åœæ­¢å½•åˆ¶
        self.pushButton_4.clicked.connect(self.stop_videorecord)

        # æŠŠè§†é¢‘å‘é€åˆ°æå‡çš„ç±»ä¸Š
        self.videostream_thread.matdict_signal.connect(self.widget_video.getmat)

        # è®¾ç½®è§†é¢‘çš„å®½é«˜
        self.videostream_thread.widthheight_signal.connect(self.videoframeai_thread.setwidthheight)

        # å‘é€è§†é¢‘å¸§
        self.videostream_thread.startrecord_signal.connect(self.videoframeai_thread.putframequeue)

        # å‘å‡ºå½•åˆ¶è§†é¢‘çš„uuid
        self.videoframeai_thread.uuid_signal.connect(self.returnuuid)

        # ä¸Šä¸€å¸§ ä¸‹ä¸€å¸§
        self.pushButton_5.clicked.connect(self.prev_frame)
        self.pushButton_6.clicked.connect(self.next_frame)

        # è®¾ç½®ç›¸å…³çš„å‚æ•°å’Œéœ€æ±‚è¯´æ˜

        self.videostream_thread.sendframeindex_signal.connect(self.get_frameid_deal)

        # æŒ‰é’®åˆ—è¡¨ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†
        self.buttons = [
            self.pushButton,
            self.pushButton_2,
            self.pushButton_3,
            self.pushButton_4,
            self.pushButton_5,
            self.pushButton_6,
            #self.pushButton_7,
            self.pushButton_8,
            self.pushButton_9
        ]

        # ä¸ºæ¯ä¸ªæŒ‰é’®ç»‘å®šç‚¹å‡»äº‹ä»¶
        for btn in self.buttons:
            btn.clicked.connect(self.on_button_clicked)

    def on_button_clicked(self):
        # è·å–ç‚¹å‡»çš„æŒ‰é’®
        clicked_button = self.sender()
        # æ›´æ–°æŒ‰é’®æ ·å¼
        self.update_button_styles(clicked_button)

    def update_button_styles(self, active_button):
        # å®šä¹‰æ ·å¼
        active_style = "background-color: rgb(255,0,0); font: 18pt 'Agency FB';"
        inactive_style = "background-color: rgb(0,0,127); font: 18pt 'Agency FB';"

        # éå†æ‰€æœ‰æŒ‰é’®ï¼Œè®¾ç½®æ ·å¼
        for btn in self.buttons:
            if btn == active_button:
                btn.setStyleSheet(active_style)
            else:
                btn.setStyleSheet(inactive_style)

    def start_videoborad(self):

        if not self.videostream_thread.isRunning():
            self.videostream_thread.setrtsp(self.path)
            self.videostream_thread.start()

    def pause_videoborad(self):

        if self.videostream_thread.isRunning():
            self.videostream_thread.pause()

    def resume_videoborad(self):

        if self.videostream_thread.isRunning():
            self.videostream_thread.resume()
    def stop_videoborad(self):

        QApplication.processEvents()
        if self.videostream_thread.isRunning():
            self.videostream_thread.stop()

    def setflag_startai(self):
        self.flag_startai = True

    def start_videorecord(self):
        if(self.videostream_thread.isRunning() and self.flag_startai):
            self.videostream_thread.setstartrecord()
            if not self.videoframeai_thread.isRunning():
                self.videoframeai_thread.start()
    def stop_videorecord(self):

        if(self.videostream_thread.isRunning()):
            self.videostream_thread.setstoprecord()
            self.videoframeai_thread.stop()

    def next_frame(self):

        if(self.videostream_thread.isRunning() and self.flag_nextpre):
            self.videostream_thread.next_frame()
    def prev_frame(self):
        if (self.videostream_thread.isRunning() and self.flag_nextpre):
            self.videostream_thread.prev_frame()

    def returnuuid(self,tmpuuid):
        self.uuid_signal.emit(tmpuuid)

    def setsavepath(self,path):
        self.videoframeai_thread.setsavepath(path)

    def setrtsp(self, path):
        self.path = path
    def setcombinejson(self, jsonpath, uuid1, uuid2):
        self.jsonpath = jsonpath  # xxx/xxx/xx.json
        self.uuid1 = uuid1  # xxx1
        self.uuid2 = uuid2  # xxx2

    #è¿™ä¸ªè¦è®¾ç½®çš„
    def setnextpreflag(self):
        self.flag_nextpre = True

    def setflagloop(self):
        self.videostream_thread.setflagloop()
    def setstorepath(self, storepath):
        self.storepath = storepath
    def readjsondata(self):

        try:

            if(os.path.exists(self.jsonpath)):
                with open(self.jsonpath, "r", encoding="utf-8") as f:
                    self.listdata = json.load(f)

            # id1 jsonè·¯å¾„
            id1json_path = os.path.join(self.storepath, self.uuid1 + ".json")
            id2json_path = os.path.join(self.storepath, self.uuid2 + ".json")
            # æå–å…³é”®ç‚¹æ•°æ®
            if(os.path.exists(id1json_path) and os.path.exists(id2json_path)):
                with open(id1json_path, 'r') as f:
                    self.id1json_data = json.load(f)

                with open(id2json_path, 'r') as f:
                    self.id2json_data = json.load(f)

        except Exception as e:
            print(e)

    # ========== è§’åº¦å·®å¼‚å‡½æ•° ==========
    def calculate_angle(self,a, b, c):
        ba = a - b
        bc = c - b
        cosine = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-8)
        angle = np.arccos(np.clip(cosine, -1.0, 1.0))
        return np.degrees(angle)

    # è§’åº¦è®¡ç®—å‡½æ•°ï¼ˆä¸ç«–ç›´æ–¹å‘çš„å¤¹è§’ï¼‰
    def calculate_torso_angle(self, neck, hip_center):
        vector = hip_center - neck
        vertical = np.array([0, 1])  # å‘ä¸‹ä¸ºç«–ç›´æ–¹å‘
        cos_theta = np.dot(vector, vertical) / (np.linalg.norm(vector) * np.linalg.norm(vertical))
        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # é˜²æ­¢æ•°å€¼è¯¯å·®
        return np.degrees(angle)

    # ========== å§¿æ€ç»“æ„å½’ä¸€åŒ–å¯¹æ¯” ==========
    def normalize_keypoints(self,kp):
        # origin = (kp[0]+kp[1])/2  # è‚©è†€ä¸­é—´
        rect = cv2.minAreaRect(kp.astype(np.float32))  # ä¿è¯è¾“å…¥ç±»å‹æ­£ç¡®
        origin = np.array(rect[0])  # ä¸­å¿ƒç‚¹ (x, y)

        kp = kp - origin
        scale = np.linalg.norm(kp)
        return kp / (scale + 1e-8)

    def generate_pose_report_to_file(self,structure_diff, angle_diffs, euclidean_distance, avg_angle_diff,
                                     filename="pose_report.txt"):
        parts = ['å·¦è‡‚', 'å³è‡‚', 'å·¦è…¿', 'å³è…¿', 'èº¯å¹²']
        angle_comment = ""
        for part, angle in zip(parts, angle_diffs):
            if angle < 10:
                level = "é«˜åº¦ä¸€è‡´"
            elif angle < 25:
                level = "è½»å¾®å·®å¼‚"
            elif angle < 45:
                level = "ä¸­ç­‰å·®å¼‚"
            else:
                level = "æ˜æ˜¾åå·®"
            angle_comment += f"  - {part}è§’åº¦å·®ï¼š{angle:.2f}Â°ï¼ˆ{level}ï¼‰\n"

        structure_eval = (
            "ç»“æ„æä¸ºæ¥è¿‘ï¼ŒåŠ¨ä½œè¡¨ç°é«˜åº¦ä¸€è‡´" if structure_diff > 0.9 else
            "ç»“æ„å¤§ä½“ç›¸ä¼¼ï¼Œä½†å­˜åœ¨ä¸€ç‚¹å·®å¼‚" if structure_diff > 0.5 else
            "ç»“æ„æœ‰æ‰€å·®å¼‚"
        )

        distance_eval = (
            "ä½ç½®å¯¹é½è‰¯å¥½ï¼Œå…³é”®ç‚¹åˆ†å¸ƒæ¥è¿‘" if euclidean_distance < 100 else
            "å…³é”®ç‚¹ç•¥æœ‰åç§»" if euclidean_distance < 200 else
            "å…³é”®ç‚¹åç§»æ˜¾è‘—ï¼Œå¯èƒ½å­˜åœ¨å®šä½è¯¯å·®æˆ–åŠ¨ä½œå·®å¼‚"
        )

        angle_diff_eval = (
            "æ•´ä½“å…³èŠ‚è¿åŠ¨ç›¸ä¼¼ï¼Œå§¿æ€åè°ƒæ€§è‰¯å¥½" if avg_angle_diff < 10 else
            "å­˜åœ¨ä¸€å®šåŠ¨ä½œå·®å¼‚ï¼Œå»ºè®®æ³¨æ„è‚¢ä½“è§’åº¦æ§åˆ¶" if avg_angle_diff < 25 else
            "è§’åº¦å·®å¼‚è¾ƒå¤§ï¼Œéœ€é‡ç‚¹çº æ­£åŠ¨ä½œå§¿æ€"
        )

        worst_part = parts[angle_diffs.index(max(angle_diffs))]

        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        report = f"""ğŸ” åŠ¨ä½œç›¸ä¼¼æ€§åˆ†ææŠ¥å‘Š
    ç”Ÿæˆæ—¶é—´ï¼š{now}

    1. æ•´ä½“ç»“æ„åˆ†æ
       - ç»“æ„ç›¸ä¼¼å€¼ï¼š{structure_diff:.4f}
       - è¯„ä»·ï¼š{structure_eval}

    2. å…³é”®å…³èŠ‚è§’åº¦å·®å¼‚
    {angle_comment}

    3. å¹³å‡æ¬§æ°è·ç¦»
       - è·ç¦»ï¼š{euclidean_distance:.2f}px
       - è¯„ä»·ï¼š{distance_eval}

    4. å¹³å‡è§’åº¦å·®å¼‚
       - å¹³å‡è§’åº¦å·®ï¼š{avg_angle_diff:.2f}Â°
       - è¯„ä»·ï¼š{angle_diff_eval}
       
    ğŸ§  ç»¼åˆå»ºè®®ï¼š
        > ä¸»è¦åŠ¨ä½œå·®å¼‚é›†ä¸­åœ¨â€œ{worst_part}â€ï¼Œå»ºè®®é’ˆå¯¹è¯¥éƒ¨ä½è¿›è¡Œä¸“é¡¹è®­ç»ƒæˆ–æ ¡æ­£ï¼›
        > æ€»ä½“æ¥çœ‹ï¼Œç»“æ„{structure_eval.replace("ç»“æ„", "")}ã€‚
        > æ¨èæ ¹æ®æŠ¥å‘Šä¸­çš„å…·ä½“éƒ¨ä½å·®å¼‚åˆ¶å®šçº æ­£åŠ¨ä½œè®¡åˆ’ã€‚

      
    â€”â€” End of Report â€”
    """

        with open(filename, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜ä¸ºï¼š{filename}")

        return report
    #å›ä¼ ç›¸å…³çš„å¯¹æ¯”æ•°æ®
    def get_frameid_deal(self,frameid):
        try:
            # if os.path.exists(self.jsonpath):
            if (frameid<len(self.listdata)):

                # æå–å‡ºæ¥åŒ¹é…çš„id1å’Œid2
                frame_id1id2 = self.listdata[frameid]

                # æå–å…³é”®ç‚¹æ•°æ®   æ³¨æ„è¿™é‡Œé¢çš„æ ‡ç­¾æ˜¯ key "0":data  darashape:[17,2]
                # keypointid1 = self.id1json_data[str(frame_id1id2[0])]
                # keypointid2 = self.id2json_data[str(frame_id1id2[1])]
                #
                # print("keypointid1:",keypointid1)
                # print("keypointid2:",keypointid2)

                # æ³¨æ„è¿™é‡Œè¦è½¬æ¢æˆ
                kp1 = np.array(self.id1json_data[str(frame_id1id2[0])][0:17])
                kp2 = np.array(self.id2json_data[str(frame_id1id2[1])][0:17])

                print("keypointid1:",kp1)
                print("keypointid2:",kp2)


                # ç¤ºä¾‹è§’åº¦å¯¹æ¯”ï¼ˆå·¦è‡‚ã€å³è‡‚ã€å·¦è…¿ã€å³è…¿ï¼‰
                angles1 = [
                    self.calculate_angle(kp1[5], kp1[7], kp1[9]),  # å·¦è‚©-è‚˜-è…•
                    self.calculate_angle(kp1[6], kp1[8], kp1[10]),  # å³è‚©-è‚˜-è…•
                    self.calculate_angle(kp1[11], kp1[13], kp1[15]),  # å·¦é«‹-è†-è¸
                    self.calculate_angle(kp1[12], kp1[14], kp1[16]),  # å³é«‹-è†-è¸
                    self.calculate_torso_angle((kp1[5]+kp1[6]) / 2,(kp1[11] + kp1[12]) / 2)
                ]
                angles2 = [
                    self.calculate_angle(kp2[5], kp2[7], kp2[9]),
                    self.calculate_angle(kp2[6], kp2[8], kp2[10]),
                    self.calculate_angle(kp2[11], kp2[13], kp2[15]),
                    self.calculate_angle(kp2[12], kp2[14], kp2[16]),
                    self.calculate_torso_angle((kp2[5] + kp2[6]) / 2, (kp2[11] + kp2[12]) / 2)
                ]
                angle_diff = np.abs(np.array(angles1) - np.array(angles2))

                # ========== æ¬§æ°è·ç¦» ==========[]
                euclidean_diff = np.linalg.norm(kp1[5:17] - kp2[5:17], axis=1)
                mean_distance = np.mean(euclidean_diff)

                # ========== å§¿æ€ç»“æ„å½’ä¸€åŒ–å¯¹æ¯” ==========
                norm1 = self.normalize_keypoints(kp1[5:17])
                norm2 = self.normalize_keypoints(kp2[5:17])
                structure_diff = np.linalg.norm(norm1 - norm2)
                structure_similarity = np.exp(-structure_diff)


                # paramstr = ""
                # # paramstr+=f"æ•´ä½“ç»“æ„å·®å¼‚:{structure_diff}\n"
                # paramstr+=f"æ•´ä½“ç»“æ„ç›¸ä¼¼æ€§:{structure_similarity}\n"
                # paramstr+=f"è§’åº¦å·®ï¼ˆå·¦è‡‚ã€å³è‡‚ã€å·¦è…¿ã€å³è…¿ã€èº¯å¹²è§’åº¦å·®ï¼ˆè„–å­â†’é«‹éƒ¨ï¼‰:{angle_diff}\n"
                # paramstr+=f"å¹³å‡æ¬§æ°è·ç¦»:{mean_distance}\n"
                # paramstr+=f"å¹³å‡è§’åº¦å·®:{np.mean(angle_diff)}\n"
                # self.paramstr_signal.emit(paramstr)
                #
                # print("æ•´ä½“ç»“æ„å·®å¼‚:", structure_diff)
                # print("è§’åº¦å·®ï¼ˆå·¦è‡‚ã€å³è‡‚ã€å·¦è…¿ã€å³è…¿ã€èº¯å¹²è§’åº¦å·®ï¼ˆè„–å­â†’é«‹éƒ¨ï¼‰:", angle_diff)
                # print("å¹³å‡æ¬§æ°è·ç¦»:", mean_distance)
                # print("å¹³å‡è§’åº¦å·®:", np.mean(angle_diff))

                paramstr = self.generate_pose_report_to_file(structure_similarity, angle_diff.tolist(), mean_distance, np.mean(angle_diff))
                print(paramstr)
                self.paramstr_signal.emit(paramstr)


        except Exception as e:
            print(e)



if __name__ == '__main__':

    app = QApplication(sys.argv)
    window = lyVideoPlayer()
    window.show()
    sys.exit(app.exec_())